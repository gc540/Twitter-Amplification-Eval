{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers sentencepiece accelerate safetensors datasets torchvision beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline \n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data collected in R (wherever it was saved, either Google Drive or locally)\n",
    "\n",
    "# Remove lowtrust posts from users timelines to avoid leakages \n",
    "user_timelines_covid = user_timelines_covid[~user_timelines_covid['id'].isin(covid_lowtrust_tweets['id'])]\n",
    "user_timelines_climate = user_timelines_climate[~user_timelines_climate['id'].isin(climate_lowtrust_tweets['id'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Stratification I - Sentiment Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load FLAN T5-XXL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from HuggingFace\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xxl\", device_map=\"auto\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Model Accuracy using Sentiment140 Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "import pandas as pd\n",
    "\n",
    "# Import the benchmarking dataset\n",
    "twtsent_benchmark = load_dataset(\"sentiment140\")\n",
    "twtsent_benchmark = twtsent_benchmark['train']\n",
    "twtsent_benchmark = pd.DataFrame(twtsent_benchmark)\n",
    "\n",
    "sentiment_mapping = {\n",
    "    0: 'negative',\n",
    "    2: 'neutral',\n",
    "    4: 'positive'\n",
    "}\n",
    "\n",
    "# Sentiment140 uses numeric values to classify sentiment (0 is negative, 2 is neutral and 4 is positive). Here, we change that to the text label \n",
    "twtsent_benchmark['sentiment'] = twtsent_benchmark['sentiment'].replace(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def sentiment_analysis_benchmark(dataset, model, tokenizer, batch_size=128):\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(dataset), batch_size):\n",
    "            batch = dataset.iloc[i:i+batch_size]\n",
    "            input_texts = [\"Classify the sentiment of the following tweet as positive, negative or neutral. Tweet: \" + text for text in batch['text']]\n",
    "            input_ids = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(\"cuda\")\n",
    "            outputs = model.generate(input_ids)\n",
    "            labels = [tokenizer.decode(output) for output in outputs]\n",
    "            for j, label in enumerate(labels):\n",
    "                index = i + j\n",
    "                results.append({\"index\": index, \"zs_label\": label, \"original_label\": batch['sentiment'].iloc[j]})\n",
    "            del batch, input_texts, input_ids, outputs, labels\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "twtsent_benchmark_speedtest = sentiment_analysis_benchmark(twtsent_benchmark, model, tokenizer, batch_size=128)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flan outputs sentiment labels with >< around them, here we remove them to only keep the raw label\n",
    "\n",
    "def extract_middle_word(text):\n",
    "    return text.split(\"> \")[1].split(\"</\")[0]\n",
    "\n",
    "twtsent_benchmark_speedtest['zs_label'] = twtsent_benchmark_speedtest['zs_label'].apply(extract_middle_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "raw_accuracy = (twtsent_benchmark_speedtest[\"original_label\"] == twtsent_benchmark_speedtest[\"zs_label\"]).mean()\n",
    "print(\"Accuracy:\", raw_accuracy)\n",
    "\n",
    "matthews_corr = matthews_corrcoef(twtsent_benchmark_speedtest['original_label'],twtsent_benchmark_speedtest['zs_label'])\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Sentiment Analysis to Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def preprocess_text(df):\n",
    "    # Remove URLs\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(url_pattern, '', x))\n",
    "\n",
    "    # Remove hashtags\n",
    "    hashtag_pattern = r'#[a-zA-Z0-9_]+'\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(hashtag_pattern, '', x))\n",
    "\n",
    "    # Remove mentions and the words following @\n",
    "    mention_pattern = r'@[a-zA-Z0-9_]+'\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(mention_pattern, '', x))\n",
    "\n",
    "    # Remove special characters like \"\n",
    "    special_chars_pattern = r'[\"]'\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(special_chars_pattern, '', x))\n",
    "\n",
    "    # Remove extra whitespaces\n",
    "    df['text'] = df['text'].apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "    # Remove the text in rows where there is only one word\n",
    "    df['text'] = df['text'].apply(lambda x: '' if len(x.split()) == 1 else x)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_lowtrust_tweets = preprocess_text(covid_lowtrust_tweets)\n",
    "climate_lowtrust_tweets = preprocess_text(climate_lowtrust_tweets)\n",
    "user_timelines_covid = preprocess_text(user_timelines_covid)\n",
    "user_timelines_climate = preprocess_text(user_timelines_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is different from the previous one as we don't have benchmarking labels, so we only keep the label output from the T5 model. This function should smoothly on a 80gb GPU, but batch sizes can be changed if needed. It is also possible to run it on a 40gb GPU with smaller batch-sizes and a longer computing time. \n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def sentiment_classifier(dataset, model, tokenizer, batch_size):\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(dataset), batch_size):\n",
    "            batch = dataset.iloc[i:i+batch_size]\n",
    "            input_texts = [\"Classify the sentiment of the following tweet as positive, negative or neutral. Tweet: \" + text for text in batch['text']]\n",
    "            input_ids = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(\"cuda\")\n",
    "            outputs = model.generate(input_ids)\n",
    "            labels = [tokenizer.decode(output) for output in outputs]\n",
    "            for j, label in enumerate(labels):\n",
    "                index = i + j\n",
    "                results.append({\"id\": batch.iloc[j]['id'], \"sentiment_label\": label})\n",
    "            del batch, input_texts, input_ids, outputs, labels\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After defining the sentiment classifier, we can now apply it to the four datasets\n",
    "\n",
    "def classify_sentiment(dataset, model, tokenizer, batch_size):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    def extract_middle_word(text):\n",
    "     return text.split(\"> \")[1].split(\"</\")[0]\n",
    "\n",
    "    results_df = sentiment_classifier(dataset, model, tokenizer, batch_size)\n",
    "    results_df['sentiment_label'] = results_df['sentiment_label'].apply(extract_middle_word)\n",
    "    merged_df = pd.merge(dataset, results_df, on=\"id\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return merged_df\n",
    "\n",
    "covid_lowtrust_tweets = classify_sentiment(covid_lowtrust_tweets, model, tokenizer, batch_size=64)\n",
    "climate_lowtrust_tweets = classify_sentiment(climate_lowtrust_tweets, model, tokenizer, batch_size=64)\n",
    "user_timelines_covid = classify_sentiment(user_timelines_covid, model, tokenizer, batch_size=64)\n",
    "user_timelines_climate = classify_sentiment(user_timelines_climate, model, tokenizer, batch_size=64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Stratification II - Engagement Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def label_engagement_kmeans(lowtrust_tweets, user_timelines):\n",
    "    # Add a 'type' column to lowtrust_tweets and user_timelines dataframes\n",
    "    lowtrust_tweets['type'] = 'lowtrust_tweets'\n",
    "    user_timelines['type'] = 'user_timelines'\n",
    "\n",
    "    # Merge the lowtrust tweets and user timelines dataframes\n",
    "    merged_df = pd.concat([lowtrust_tweets, user_timelines])\n",
    "\n",
    "    # Convert target columns to numeric and replace missing values with 0\n",
    "    target_cols = ['retweet_count', 'reply_count', 'like_count', 'quote_count']\n",
    "    merged_df[target_cols] = merged_df[target_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "    # Apply weights for each type of engagement\n",
    "    weights = {'retweet_count': 2, 'reply_count': 54, 'like_count': 1, 'quote_count': 2}\n",
    "    for col in target_cols:\n",
    "        merged_df[col] = merged_df[col] * weights[col]\n",
    "\n",
    "    # Apply Box-Cox transformation to target columns\n",
    "    for col in target_cols:\n",
    "        transformed_data, _ = boxcox(merged_df[col] + 1) # add 1 to handle 0 values\n",
    "        merged_df[col] = transformed_data\n",
    "\n",
    "    # Calculate total weighted engagement for each post\n",
    "    merged_df['total_engagement'] = merged_df[target_cols].sum(axis=1)\n",
    "\n",
    "    # Scale the total_engagement data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_engagement = scaler.fit_transform(merged_df[['total_engagement']])\n",
    "\n",
    "    # Use KMeans clustering to detect 3 engagement levels\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42).fit(scaled_engagement)\n",
    "    merged_df['engagement_level'] = kmeans.labels_\n",
    "\n",
    "    # Calculate the mean total engagement for each engagement level\n",
    "    mean_engagement = merged_df.groupby('engagement_level')['total_engagement'].mean()\n",
    "\n",
    "    # Label the engagement levels based on mean total engagement\n",
    "    label_map = {idx: 'low_engagement' if val <= mean_engagement.min() else 'high_engagement' if val >= mean_engagement.max() else 'mid_engagement' for idx, val in mean_engagement.items()}\n",
    "    merged_df['engagement_level'] = merged_df['engagement_level'].map(label_map)\n",
    "\n",
    "    # Split the merged dataframe back into lowtrust_tweets and user_timelines dataframes\n",
    "    merged_df = merged_df.groupby('type')\n",
    "    lowtrust_tweets = merged_df.get_group('lowtrust_tweets')\n",
    "    user_timelines = merged_df.get_group('user_timelines')\n",
    "\n",
    "    return lowtrust_tweets, user_timelines\n",
    "\n",
    "climate_lowtrust_tweets, user_timelines_climate = label_engagement_kmeans(climate_lowtrust_tweets, user_timelines_climate)\n",
    "covid_lowtrust_tweets, user_timelines_covid = label_engagement_kmeans(covid_lowtrust_tweets, user_timelines_covid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify Sample and Compare Impressions Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def scale_data(dataframe):\n",
    "    scaler = RobustScaler(quantile_range=(25, 75))\n",
    "    dataframe['impressions_count'] = scaler.fit_transform(dataframe[['impressions_count']])\n",
    "    dataframe['impressions_count'] += abs(min(dataframe['impressions_count'].min(), 0))\n",
    "    return dataframe\n",
    "\n",
    "def calculate_average_impressions_by_user(user_timelines):\n",
    "    user_timelines = user_timelines.copy()\n",
    "    user_timelines['stratum'] = user_timelines['sentiment_label'] + '.' + user_timelines['engagement_level'].str.lower()\n",
    "    results = user_timelines.groupby(['author_id', 'stratum'])['impressions_count'].median().reset_index()\n",
    "    results.rename(columns={'impressions_count': 'average_impressions'}, inplace=True)\n",
    "    return results\n",
    "\n",
    "def performance_computation(lowtrust_tweets, user_timelines):\n",
    "    lowtrust_tweets_scaled = scale_data(lowtrust_tweets.copy())\n",
    "    user_timelines_scaled = scale_data(user_timelines.copy())\n",
    "    average_impressions_by_user = calculate_average_impressions_by_user(user_timelines_scaled)\n",
    "    lowtrust_tweets_scaled['stratum'] = lowtrust_tweets_scaled['sentiment_label'] + '.' + lowtrust_tweets_scaled['engagement_level'].str.lower()\n",
    "    merged_data = lowtrust_tweets_scaled.merge(average_impressions_by_user, on=['author_id', 'stratum'], how='left')\n",
    "\n",
    "    min_non_zero_value_user = merged_data[merged_data['average_impressions'] > 0]['average_impressions'].min()\n",
    "    min_non_zero_value_lowt = merged_data[merged_data['impressions_count'] > 0]['impressions_count'].min()\n",
    "    merged_data['average_impressions'] = np.where(merged_data['average_impressions'] == 0, min_non_zero_value_user, merged_data['average_impressions'])\n",
    "    merged_data['impressions_count'] = np.where(merged_data['impressions_count'] == 0, min_non_zero_value_lowt, merged_data['impressions_count'])\n",
    "\n",
    "    merged_data['impressions_performance'] = ((merged_data['impressions_count'] - merged_data['average_impressions']) / merged_data['average_impressions']) * 100\n",
    "    q005, q995 = merged_data['impressions_performance'].quantile([0.005, 0.995])\n",
    "    merged_data = merged_data.loc[(merged_data['impressions_performance'] >= q005) & (merged_data['impressions_performance'] <= q995)]\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the covid and climate dataframes\n",
    "covid_results = calculate_impressions_performance(covid_lowtrust_tweets,user_timelines_covid)\n",
    "climate_results = calculate_impressions_performance(climate_lowtrust_tweets,user_timelines_climate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape updated MBFC Bias Ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_bias_ratings_for_dataframe_full(df):\n",
    "    # Function to fetch the MBFC URL for a given domain\n",
    "    def get_mbfc_url(domain):\n",
    "        search_url = f\"https://mediabiasfactcheck.com/?s={domain}\"\n",
    "        response = requests.get(search_url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        search_result = soup.select_one(\"h3.entry-title a\")\n",
    "        if search_result:\n",
    "            return search_result[\"href\"]\n",
    "        return None\n",
    "\n",
    "    def get_bias_rating(mbfc_url):\n",
    "        response = requests.get(mbfc_url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        bias_ratings = [\"LEFT\", \"RIGHT\", \"RIGHT-EXTREME\", \"LEFT-EXTREME\", \"CENTER\", \"FAR-RIGHT\", \"FAR-LEFT\", \"RIGHT-CENTER\", \"LEFT-CENTER\", \"FAR RIGHT\", \"FAR LEFT\", \"RIGHT EXTREME\", \"LEFT EXTREME\", \"RIGHT CENTER\", \"LEFT CENTER\", \"Far right\", \"far right\"]\n",
    "        rating_div = soup.find(\"div\", class_=\"entry-content\")\n",
    "        if rating_div:\n",
    "            text = rating_div.get_text()\n",
    "\n",
    "            # Sort the bias_ratings list by length in descending order\n",
    "            bias_ratings.sort(key=len, reverse=True)\n",
    "\n",
    "            for rating in bias_ratings:\n",
    "                if rating in text:\n",
    "                    return rating\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    # Create a dictionary to store the bias ratings for each domain\n",
    "    domain_bias_dict = {}\n",
    "\n",
    "    # Iterate through the rows of the dataframe\n",
    "    for idx, row in df.iterrows():\n",
    "        domain = row['domains']\n",
    "        # If the domain has not been looked up before, fetch its bias rating\n",
    "        if domain not in domain_bias_dict:\n",
    "            print(f\"Fetching bias rating for domain: {domain}\")\n",
    "            mbfc_url = get_mbfc_url(domain)\n",
    "            if mbfc_url:\n",
    "                print(f\"MBFC URL found for domain: {domain}\")\n",
    "                bias_rating = get_bias_rating(mbfc_url)\n",
    "                if bias_rating:\n",
    "                    print(f\"Bias rating found for domain {domain}: {bias_rating}\")\n",
    "                    domain_bias_dict[domain] = bias_rating\n",
    "                else:\n",
    "                    print(f\"No bias rating found for domain: {domain}\")\n",
    "                    domain_bias_dict[domain] = None\n",
    "            else:\n",
    "                print(f\"No MBFC URL found for domain: {domain}\")\n",
    "                domain_bias_dict[domain] = None\n",
    "\n",
    "        # Update the row with the domain's bias rating\n",
    "        bias_rating = domain_bias_dict[domain]\n",
    "        if bias_rating == None:\n",
    "            bias_rating = 'Bias Rating Not Found'\n",
    "        df.at[idx, 'bias_rating'] = bias_rating\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the dataframes\n",
    "results_climate = get_bias_ratings_for_dataframe_full(results_climate)\n",
    "results_covid = get_bias_ratings_for_dataframe_full(results_covid)\n",
    "\n",
    "# Some values are worded differently in MBFC, so we need to modify them\n",
    "results_covid['bias_rating'] = results_covid['bias_rating'].replace([\"FAR-RIGHT\",\"far right\"], 'FAR RIGHT')\n",
    "results_climate['bias_rating'] = results_climate['bias_rating'].replace([\"FAR-RIGHT\",\"far right\"], 'FAR RIGHT')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling with Bertopic + GPT3.5 on Top Performers - Not Yet Implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import openai\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "def topic_modeling(data, min_cluster_size, min_samples):\n",
    "    # get 75th percentile of 'impressions_performance' column in dataframe\n",
    "    pct_75 = data['impressions_performance'].quantile(0.75)\n",
    "    \n",
    "    # select all rows where the column value is greater than or equal to the 75th percentile value\n",
    "    selected_rows = data[data['impressions_performance'] >= pct_75]\n",
    "    \n",
    "    # define a function to clean tweet text\n",
    "    def clean_tweet(tweet):\n",
    "        tweet = re.sub(r'@\\w+', '', tweet)  # Remove mentions\n",
    "        tweet = re.sub(r'#\\w+', '', tweet)  # Remove hashtags\n",
    "        tweet = re.sub(r'http\\S+', '', tweet)  # Remove URLs\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet)  # Remove extra spaces\n",
    "        tweet = re.sub(r'\\d+', '', tweet)  # Remove numbers\n",
    "        tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)  # Remove non-ASCII characters\n",
    "        tweet = tweet.strip()  # Remove extra whitespace\n",
    "        return tweet\n",
    "    \n",
    "    # apply clean_tweet function to 'text' column of selected rows\n",
    "    selected_rows['text'] = selected_rows['text'].apply(clean_tweet)\n",
    "    \n",
    "    # filter out rows where 'text' column has zero length\n",
    "    mask = selected_rows['text'].str.len() >= 1\n",
    "    selected_rows = selected_rows.loc[mask]\n",
    "    \n",
    "    # create list of tweet text strings\n",
    "    data_list = selected_rows['text'].tolist()\n",
    "    \n",
    "    # download stopwords\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    # set up stopwords list\n",
    "    stopwords_list = list(stopwords.words('english')) + ['http', 'https', 'amp', 'com']\n",
    "    \n",
    "    # set up CountVectorizer with stopword list\n",
    "    vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=stopwords_list)\n",
    "    \n",
    "    # set up OpenAI representation model\n",
    "    openai.api_key = \"YOUR_API_KEY\"\n",
    "    prompt = \"\"\"\n",
    "    I have a topic that contains the following documents: \n",
    "    [DOCUMENTS]\n",
    "    The topic is described by the following keywords: [KEYWORDS]\n",
    "\n",
    "    Based on the information above, extract a very short topic label in the following format:\n",
    "    topic: <topic label>\n",
    "    \"\"\"\n",
    "    representation_model = OpenAI(model=\"gpt-3.5-turbo\", delay_in_seconds=10, chat=True, prompt=prompt)\n",
    "    \n",
    "    # set up SentenceTransformer embedding model and UMAP and HDBSCAN clustering models\n",
    "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    umap_model = UMAP(n_neighbors=3, n_components=3, min_dist=0.05, random_state=42)\n",
    "    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, gen_min_span_tree=True, prediction_data=True)\n",
    "    \n",
    "    # set up BERTopic model with above components and fit on tweet text data\n",
    "    model = BERTopic(\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        embedding_model=embedding_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        representation_model=representation_model,\n",
    "        top_n_words=15,\n",
    "        language='english',\n",
    "        calculate_probabilities=True,\n",
    "        verbose=True\n",
    "        )\n",
    "    \n",
    "    topics, probs = model.fit_transform(data_list)\n",
    "    return topics, probs, model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb5e7f640ffd48b5057e62ed5568e08322721c9cc2209814d905c7b5e58d5c77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
